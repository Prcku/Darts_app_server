import cv2
import numpy as np
import yaml
import json
import time

class KalmanTracker:
    """Trieda pre sledovanie objektov pomocou Kalmanovho filtra."""
    def __init__(self):
        # Inicializ√°cia Kalmanovho filtra pre sledovanie v 2D priestore (x, y)
        self.kalman = cv2.KalmanFilter(4, 2)
        self.kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)
        self.kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)
        self.kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03
        
        self.last_prediction = None
        self.initialized = False
        
    def update(self, x, y):
        """Aktualizuje filter s nov√Ωm meran√≠m."""
        measurement = np.array([[x], [y]], np.float32)
        
        if not self.initialized:
            # Inicializ√°cia stavu filtra
            self.kalman.statePre = np.array([[x], [y], [0], [0]], np.float32)
            self.kalman.statePost = np.array([[x], [y], [0], [0]], np.float32)
            self.initialized = True
        
        # Predikcia
        prediction = self.kalman.predict()
        
        # Korekcia s nov√Ωm meran√≠m
        corrected = self.kalman.correct(measurement)
        
        # Ulo≈æenie v√Ωsledku
        self.last_prediction = corrected[:2].reshape(-1)
        return self.last_prediction
    
    def get_position(self):
        """Vr√°ti aktu√°lnu poz√≠ciu."""
        if self.last_prediction is not None:
            return (int(self.last_prediction[0]), int(self.last_prediction[1]))
        return None

def load_calibration(file):
    """Naƒç√≠ta kalibraƒçn√© √∫daje z YAML s√∫boru."""
    with open(file, "r") as f:
        data = yaml.safe_load(f)

    camera_matrix = np.array(data["camera_matrix"], dtype=np.float32)
    dist_coeffs = np.array(data["distortion_coefficients"], dtype=np.float32)

    # Vytvorenie optimalizovanej kamery a remapovac√≠ch m√°p
    h, w = 1000, 1000
    new_camera_mtx, roi = cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeffs, (w, h), 0, (w, h))

    if new_camera_mtx is None or not isinstance(new_camera_mtx, np.ndarray):
        print("‚ö†Ô∏è new_camera_mtx nie je validn√°! Pou≈æ√≠vam p√¥vodn√∫ camera_matrix.")
        new_camera_mtx = camera_matrix

    mapx, mapy = cv2.initUndistortRectifyMap(camera_matrix, dist_coeffs, None, new_camera_mtx, (w, h), cv2.CV_32FC1)

    return camera_matrix, dist_coeffs, new_camera_mtx, mapx, mapy

def capture_reference_images(cameras, calibration_data):
    """Zachyt√≠ referenƒçn√© obr√°zky s viacer√Ωmi sn√≠mkami pre stabilnej≈°√≠ referenƒçn√Ω obraz."""
    ref_images = []
    
    for i, cap in enumerate(cameras):
        # Zachyt√≠me viac sn√≠mok a spriemerujeme ich pre lep≈°iu referenƒçn√∫ sn√≠mku
        frames_count = 5
        frames = []
        
        for _ in range(frames_count):
            ret, frame = cap.read()
            if ret:
                frame = cv2.remap(frame, calibration_data[i][3], calibration_data[i][4], cv2.INTER_LINEAR)
                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))
            time.sleep(0.05)  # Kr√°tka pauza medzi sn√≠mkami
        
        if frames:
            # Vytvor√≠me priemer zo v≈°etk√Ωch sn√≠mok
            avg_frame = np.mean(frames, axis=0).astype(np.uint8)
            # Aplikujeme Gaussovsk√Ω filter pre odstr√°nenie zvy≈°kov√©ho ≈°umu
            avg_frame = cv2.GaussianBlur(avg_frame, (3, 3), 0.5)
            ref_images.append(avg_frame)
        else:
            ref_images.append(None)
            
    return ref_images

def adaptive_threshing(frame, ref_image):
    """Vylep≈°en√° prahovacia funkcia s adapt√≠vnym prahovan√≠m a viacer√Ωmi met√≥dami."""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    diff = cv2.absdiff(ref_image, gray)
    
    # Aplik√°cia filtrov pre redukciu ≈°umu
    blurred = cv2.GaussianBlur(diff, (3, 3), 2)
    
    # Z√°kladn√© prahovanie
    # _, thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)
    _, thresh = cv2.threshold(blurred, 20, 255, cv2.THRESH_BINARY)
    adaptive = cv2.adaptiveThreshold(
    blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
    cv2.THRESH_BINARY_INV, 11, 2
    )
    combined = cv2.bitwise_or(thresh, adaptive)

    # Canny detektor hr√°n s optimalizovan√Ωmi parametrami
    edges = cv2.Canny(blurred, 30, 90)
    
    # === MORFOLOGIA ===
    kernel_erode = np.ones((2, 2), np.uint8)
    kernel_dilate = np.ones((3, 3), np.uint8)
    morph = cv2.erode(thresh, kernel_erode, iterations=1)
    morph = cv2.morphologyEx(morph, cv2.MORPH_CLOSE, kernel_dilate, iterations=2)
    
    # Filtrovanie mal√Ωch kont√∫r
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    return contours, thresh, morph

def detect_arrowV1(frame, ref_image):
    """Detekcia ≈°√≠pky pomocou kombin√°cie najlep≈°√≠ch techn√≠k podƒæa vizu√°lnej anal√Ωzy."""
    import cv2
    import numpy as np

    # Prevod na odtie≈à ≈°edej a v√Ωpoƒçet rozdielu od referenƒçn√©ho obrazu
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    gray_blur = cv2.GaussianBlur(gray, (3, 3), 1.0)
    ref_blur = cv2.GaussianBlur(ref_image, (3, 3), 1.0)
    diff = cv2.absdiff(ref_blur, gray_blur)

    # Gaussov filter (7x7, sigma=2.0)
    # blurred = cv2.GaussianBlur(diff, (3, 3), 2.0)

    # Thresholdovanie
    _, thresh = cv2.threshold(diff, 15, 255, cv2.THRESH_BINARY)

    # Adapt√≠vne thresholdovanie (block size = 11, C = 3)
    adaptive = cv2.adaptiveThreshold(
        diff, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY_INV, 7, 3
    )

    # Kombin√°cia thresholdov
    combined = cv2.bitwise_or(thresh, adaptive)

    # Canny detekcia hr√°n
    # edges = cv2.Canny(blurred, 30, 90)

    # Morfologick√© oper√°cie ‚Äì dilat√°cia + closing
    kernel_dilate = np.ones((4, 4), np.uint8)
    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_dilate, iterations=2)

    # N√°js≈• kont√∫ry
    contours, _ = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # M√¥≈æe≈° si prida≈• ƒèal≈°ie filtrovanie kont√∫r tu (napr. podƒæa veƒækosti, pomeru str√°n...)

    return contours, thresh, morph

def detect_dart_tip(contours, frame, min_area=1000 ):
    """Vylep≈°en√° detekcia hrotu ≈°√≠pky s pou≈æit√≠m viacer√Ωch krit√©ri√≠."""
    dart_candidates = []
    
    

    for contour in contours:
        area = cv2.contourArea(contour)
        
        if area < min_area:
            continue
        
        # ƒéal≈°ie krit√©ri√° pre filtrovanie
        x, y, w, h = cv2.boundingRect(contour)
        
        # Kontrola pomeru str√°n
        aspect_ratio = w / float(h) if h > 0 else 0
        print(f"[DEBUG] Detekovan√Ωch kont√∫r: {len(contours)} a area = {area} a aspect_ration = {aspect_ratio}")      
        if aspect_ratio > 2.5 or aspect_ratio < 0.08:  # Filtrovanie pr√≠li≈° ≈°irok√Ωch alebo √∫zkych objektov
            continue
            
        # Aproxim√°cia kont√∫ry pre anal√Ωzu tvaru
        perimeter = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)  
        
        # V√Ωpoƒçet najni≈æ≈°ieho bodu kont√∫ry (hrot ≈°√≠pky)
        bottom_threshold = y + int(0.8 * h)
        bottom_points = [pt[0] for pt in contour if pt[0][1] >= bottom_threshold]
        
        if not bottom_points:
            continue
            
        lowest_point = max(bottom_points, key=lambda point: point[1])
        
        # V√Ωpoƒçet sk√≥re pre t√∫to kont√∫ru na z√°klade r√¥znych metr√≠k
        # - v√§ƒç≈°ia plocha je lep≈°ia, ale nie pr√≠li≈° veƒæk√°
        # - ni≈æ≈°ia poz√≠cia je lep≈°ia (≈°√≠pka smeruje nadol)
        # - vhodn√Ω pomer str√°n
        score = min(area / 1000, 3) + (lowest_point[1] / 100) - abs(aspect_ratio - 1.0)
        # score = 500

        # === ZOBRAZENIE DETEKCIE ===
        # cv2.drawContours(frame, [contour], -1, (0, 255, 0), 2)
        cv2.circle(frame, tuple(lowest_point), 1, (0, 0, 255), -1)  # üí• hrot ≈°√≠pky
        cv2.putText(frame, "Dart Tip", (lowest_point[0] + 5, lowest_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 1)
        #cv2.drawContours(frame, [approx], -1, (0, 255, 255), 2)  # ≈ælt√° farba
        #cv2.putText(frame, f"Pts: {len(approx)}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
        
        dart_candidates.append({
            'contour': contour,
            'lowest_point': lowest_point,
            'score': score,
            'area': area,
            'rect': (x, y, w, h)
        })
    
    # Zoradenie kandid√°tov podƒæa sk√≥re
    dart_candidates.sort(key=lambda x: x['score'], reverse=True)
    
    # if dart_candidates:
    #     best_candidate = dart_candidates[0]
    #     return best_candidate
    
    return None

def detect_dart_tipNEW(contours, frame, min_area=700):
    dart_candidates = []

    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_area:
            continue

        x, y, w, h = cv2.boundingRect(contour)
        aspect_ratio = w / float(h) if h > 0 else 0
        print(f"[DEBUG] Kont√∫ra: area = {area}, aspect_ratio = {aspect_ratio}")

        if aspect_ratio > 2.5 or aspect_ratio < 0.08:
            continue

        perimeter = cv2.arcLength(contour, True)
        approx = cv2.approxPolyDP(contour, 0.03 * perimeter, True)

        # === Nov√° detekcia cez PCA ===
        tip_point = find_tip_by_orientation(contour, frame, draw_axis=True)

        # Sk√≥re: st√°le kombinujeme viacer√© faktory
        score = min(area / 1000, 3) + (tip_point[1] / 100) - abs(aspect_ratio - 1.0)

        # === Vizualiz√°cia kandid√°ta ===
        cv2.putText(frame, "Dart Tip", (tip_point[0] + 5, tip_point[1] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 0), 1)
        #cv2.drawContours(frame, [approx], -1, (0, 255, 255), 2)

        dart_candidates.append({
            'contour': contour,
            'lowest_point': tip_point,
            'score': score,
            'area': area,
            'rect': (x, y, w, h)
        })
    dart_candidates.sort(key=lambda x: x['score'], reverse=True)
    return dart_candidates[0] if dart_candidates else None

def find_tip_by_orientation(contour, frame=None, draw_axis=False):
    """Pou≈æije PCA na urƒçenie hlavn√©ho smeru ≈°√≠pky a n√°jde bod najvzdialenej≈°√≠ v tomto smere."""
    data_pts = np.array(contour, dtype=np.float32).reshape(-1, 2)
    mean, eigenvectors = cv2.PCACompute(data_pts, mean=None)
    center = tuple(mean[0])
    direction = eigenvectors[0]

    # N√°jdeme bod najƒèalej v smere direction (projekcia)
    projections = np.dot(data_pts - mean, direction.reshape(2, 1))
    max_idx = np.argmax(projections)
    tip_point = tuple(data_pts[max_idx].astype(int))

    if frame is not None and draw_axis:
        # Nakresli hlavn√∫ os ≈°√≠pky (modr√° ƒçiara)
        p1 = (int(center[0] - direction[0]*100), int(center[1] - direction[1]*100))
        p2 = (int(center[0] + direction[0]*100), int(center[1] + direction[1]*100))
        cv2.line(frame, p1, p2, (255, 0, 0), 1)  # Modr√° = PCA os

        # Oznaƒç tip
        cv2.circle(frame, tip_point, 4, (0, 0, 255), -1)  # ƒåerven√Ω = nov√Ω hrot

    return tip_point

# Hlavn√Ω program
def main():
    # Kalibr√°cia a kamery
    cam_files = [
        "../Calibration/calibration1000/calib_data/left_calibration.yaml",
        "../Calibration/calibration1000/calib_data/middle_calibration.yaml",
        "../Calibration/calibration1000/calib_data/right_calibration.yaml"
    ]

    cams = [3,1,2]  # Pou≈æ√≠vame tri kamery
    frame_size = (1000, 1000)
    cameras = []

    # Inicializ√°cia kalmanov√Ωch filtrov pre ka≈æd√∫ kameru
    kalman_filters = [KalmanTracker() for _ in range(len(cams))]

    # Otvorenie kamier s optimalizovan√Ωm nastaven√≠m
    for i in cams:
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if not cap.isOpened():
            print(f"Cannot open camera {i}")
            exit()
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, frame_size[0])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, frame_size[1])
        # Nastavenia pre zlep≈°enie kvality obrazu
        # cap.set(cv2.CAP_PROP_FPS, 30)  # Vy≈°≈°ia frekvencia sn√≠mok
        # cap.set(cv2.CAP_PROP_AUTOFOCUS, 0)  # Vypnutie automatick√©ho ostrenia (ak je to mo≈æn√©)
        # cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1)  # Automatick√° expoz√≠cia pre prisp√¥sobenie sa osvetleniu
        cameras.append(cap)

    calibration_data = [load_calibration(file) for file in cam_files]

    # Inicializ√°cia
    print("üîÑ Inicializ√°cia referenƒçn√Ωch sn√≠mok...")
    time.sleep(1)  # D√°me kamer√°m ƒças na inicializ√°ciu
    ref_images = capture_reference_images(cameras, calibration_data)
    shots = 0  
    shot_positions = {i: [] for i in range(len(cameras))} 
    stable_darts = {i: {"count": 0, "last_pos": None, "positions": []} for i in range(len(cameras))}  
    saved_images = {i: [] for i in range(len(cameras))}  
    detected_darts = {i: None for i in range(len(cameras))}  
    json_data = {"shots": []}

    print("üì∏ ƒåak√°m na hody ≈°√≠pkami...")

    while shots < 3:
        for i in range(len(cameras)):
            ret, frame = cameras[i].read()
            if not ret or ref_images[i] is None:
                continue

            # Aplik√°cia kalibr√°cie
            frame = cv2.remap(frame, calibration_data[i][3], calibration_data[i][4], cv2.INTER_LINEAR)
            
            # Pou≈æijeme vylep≈°en√∫ adapt√≠vnu threshing funkciu
            contours, thresh, morph = detect_arrowV1(frame, ref_images[i])

            # Detekcia hrotu ≈°√≠pky
            # dart_tip = detect_dart_tip(contours, frame)
            dart_tip = detect_dart_tipNEW(contours, frame)

            if dart_tip:
                lowest_point = dart_tip['lowest_point']
                rect = dart_tip['rect']
                
                # Aplik√°cia Kalmanovho filtra na poz√≠ciu hrotu
                filtered_pos = kalman_filters[i].update(lowest_point[0], lowest_point[1])
                filtered_point = (int(filtered_pos[0]), int(filtered_pos[1]))
                
                # Kontrola stability - sledujeme posledn√Ωch niekoƒæko poz√≠ci√≠
                max_positions = 5
                stable_darts[i]["positions"].append(filtered_point)
                if len(stable_darts[i]["positions"]) > max_positions:
                    stable_darts[i]["positions"].pop(0)
                
                # Kontrola stability na z√°klade rozptylu poz√≠ci√≠
                if len(stable_darts[i]["positions"]) >= 3:
                    positions = np.array(stable_darts[i]["positions"])
                    std_dev = np.std(positions, axis=0)
                    
                    # Ak je rozptyl mal√Ω (stabiln√° poz√≠cia)
                    if np.mean(std_dev) < 4.0:
                        stable_darts[i]["count"] += 1
                    else:
                        stable_darts[i]["count"] = max(0, stable_darts[i]["count"] - 1)
                
                # Vizualiz√°cia detekcie
                x, y, w, h = rect
                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                
                # Zobrazenie hrotu a filtrovanej poz√≠cie
                cv2.circle(frame, tuple(lowest_point), 2, (0, 0, 255), -1)
                cv2.circle(frame, filtered_point, 2, (255, 0, 0), -1)
                
                # Ak je detekcia stabiln√°
                if stable_darts[i]["count"] >= 3:
                    detected_darts[i] = filtered_point
                    cv2.putText(frame, "STABLE", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    
                    # Zobrazi≈• inform√°cie o stabilite
                    stability_info = f"Stability: {stable_darts[i]['count']}/3"
                    cv2.putText(frame, stability_info, (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            else:
                # ≈Ωiadna detekcia
                stable_darts[i]["count"] = max(0, stable_darts[i]["count"] - 1)
                if stable_darts[i]["count"] == 0:
                    detected_darts[i] = None

            # Zobrazenie inform√°ci√≠ na obraze
            cv2.putText(frame, f"Kamera {i} - Hody: {shots}/3", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            cv2.imshow(f"Kamera {i}", frame)
            # cv2.imshow(f"Threshold {i}", thresh)
            cv2.imshow(f"Morphology {i}", morph)
            

        # Kontrola, ƒçi m√°me detekovan√∫ ≈°√≠pku na v≈°etk√Ωch kamer√°ch
        if all(detected_darts[i] is not None for i in detected_darts):
            shots += 1
            shot_entry = {"shot_id": shots, "cameras": []}
            
            print(f"\nüéØ DETEKOVAN√Å ≈†√çPKA {shots}/3:")
            for i in range(len(cameras)):
                shot_positions[i].append(detected_darts[i])
                shot_entry["cameras"].append({
                    "camera_id": i,
                    "x": int(detected_darts[i][0]),
                    "y": int(detected_darts[i][1])
                })
                print(f"üìå Kamera {i}: Hrot ≈°√≠pky na X={detected_darts[i][0]}, Y={detected_darts[i][1]}")
                
                # Ulo≈æenie sn√≠mky s detekciou
                ret, final_frame = cameras[i].read()
                if ret:
                    final_frame = cv2.remap(final_frame, calibration_data[i][3], calibration_data[i][4], cv2.INTER_LINEAR)
                    cv2.circle(final_frame, detected_darts[i], 2, (0, 0, 255), -1)
                    cv2.putText(final_frame, f"Shot {shots}", (detected_darts[i][0] - 30, detected_darts[i][1] - 20), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    saved_images[i].append(final_frame)
                    cv2.imwrite(f"./DetectedDartsFoto/detected_dart_camera_{i}_shot_{shots}.png", final_frame)
                    cv2.imwrite(f"./DetectedDartsFoto/detected_dart_cameraMOPRHaa_{i}_shot_{shots}.png", morph)

            
            json_data["shots"].append(shot_entry)
            
            # Reset detekci√≠ a obnovenie referenƒçn√Ωch sn√≠mok
            print("‚è≥ ƒåak√°m na ƒèal≈°√≠ hod...")
            time.sleep(0.5)  # Kr√°tke ƒçakanie
            ref_images = capture_reference_images(cameras, calibration_data)
            detected_darts = {i: None for i in range(len(cameras))}
            stable_darts = {i: {"count": 0, "last_pos": None, "positions": []} for i in range(len(cameras))}
            # Reset Kalmanov√Ωch filtrov pre nov√Ω hod
            kalman_filters = [KalmanTracker() for _ in range(len(cams))]

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Ulo≈æenie v√Ωsledkov
    with open("detected_darts.json", "w") as json_file:
        json.dump(json_data, json_file, indent=4)

    print("\nüéØ FIN√ÅLNE POZ√çCIE DETEKOVAN√ùCH ≈†√çPOK:")
    for i in shot_positions:
        for idx, tip in enumerate(shot_positions[i]):
            print(f"üìå Kamera {i}, Hod {idx+1}: X={tip[0]}, Y={tip[1]}")
    
    # Vytvorenie s√∫hrnn√©ho obr√°zka
    for i in range(len(cameras)):
        if saved_images[i]:
            # Vytvorenie gridov√©ho zobrazenia v≈°etk√Ωch hodov
            grid_height = len(saved_images[i]) * frame_size[1]
            grid_img = np.zeros((grid_height, frame_size[0], 3), dtype=np.uint8)
            
            for j, img in enumerate(saved_images[i]):
                start_y = j * frame_size[1]
                grid_img[start_y:start_y + frame_size[1], :] = img
                
            cv2.imshow(f"V√Ωsledky kamery {i}", grid_img)
            cv2.imwrite(f"./DetectedDartsFoto/camera_{i}_all_shots.png", grid_img)

    for cap in cameras:
        cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()